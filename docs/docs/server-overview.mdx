---
title: Server Overview
sidebar_position: 3
---

# Server Overview

The FastAPI server powers Archon’s knowledge ingestion, retrieval, and project management workflows. It runs locally alongside the React UI and talks to Supabase plus your configured LLM provider.

## Architecture

### Service Responsibilities

| Service | Default Port | Purpose | Contains |
|---------|--------------|---------|----------|
| **Server** | 8181 | Core API & business logic | FastAPI app, Socket.IO, RAG orchestration |
| **Frontend** | 3737 | Web UI | React application served by Vite |

Legacy MCP and agent services remain in the repository but are disabled by default.

### Communication Flow

```
Frontend (HTTP/WebSocket) → FastAPI Server → Supabase & LLM Providers
```

The UI communicates with the server over REST and Socket.IO. The server stores metadata in Supabase and calls OpenAI, Google Gemini, or Anthropic Claude depending on the models you configure.

## Key Components

### FastAPI Application
- REST API endpoints under `/api/*`
- Socket.IO server for streaming updates and task progress
- Background workers for crawling and document processing

### Service Layer
Business logic is organized into modules under `python/src/server/services/`:
- **RAG Services**: Crawling, search, document storage, and embeddings
- **Project Services**: Project, feature, and task management
- **Credential Services**: Secure storage of provider API keys
- **Utility Services**: Notifications, logging, and configuration helpers

### External Services
- **Supabase**: PostgreSQL + pgvector for data storage (cloud or local CLI)
- **LLM Providers**: OpenAI, Google Gemini, and Anthropic Claude for chat and embeddings

## API Structure

| Router | Path | Purpose |
|--------|------|---------|
| `knowledge_api.py` | `/api/knowledge-items` | Knowledge management, crawling |
| `projects_api.py` | `/api/projects` | Project and task management |
| `settings_api.py` | `/api/settings` | Configuration management |
| `provider_api.py` | `/api/providers` | Model selection and credential checks |
| `agent_chat_api.py` | `/api/agent-chat` | Chat completions and streaming |

## Environment Configuration

Key environment variables are defined in `.env`:

```bash
# Database
SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_KEY=your_service_key

# Optional overrides
ARCHON_SERVER_PORT=8181
HOST=127.0.0.1

# Logging
LOGFIRE_ENABLED=false
# LOGFIRE_TOKEN=your_logfire_token
```

Provider API keys are stored via the UI and encrypted in the database—no need to place them in `.env` unless you are automating setup.

## Development Setup

1. **Install dependencies**
   ```bash
   cd python
   uv sync
   ```

2. **Run the server with reload**
   ```bash
   uv run uvicorn src.server.main:app --reload --host 0.0.0.0 --port 8181
   ```

3. **Start the frontend**
   ```bash
   cd ../archon-ui-main
   npm run dev
   ```

4. **Open the UI**
   Visit [http://localhost:3737](http://localhost:3737) and complete onboarding. The UI proxies API requests to `http://127.0.0.1:8181` by default.

## Monitoring & Logs

- **Server logs**: Printed to the terminal running `uvicorn`
- **Supabase**: Use the Supabase dashboard or CLI (`supabase logs`) to inspect database activity
- **Logfire (optional)**: Enable by setting `LOGFIRE_ENABLED=true` and providing a `LOGFIRE_TOKEN`

For production deployments you can keep the same commands under a process manager such as `systemd`, `pm2`, or `supervisord` on Linux/Windows.

